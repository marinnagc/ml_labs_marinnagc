{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = split_features_target(train_data, test_data)\n",
    "\n",
    "# Vamos usar o log10 do target.\n",
    "y_train = np.log10(y_train)\n",
    "y_test = np.log10(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [\n",
    "    'longitude',\n",
    "    'latitude',\n",
    "    'housing_median_age',\n",
    "    'total_rooms',\n",
    "    'total_bedrooms',\n",
    "    'population',\n",
    "    'households',\n",
    "    'median_income',\n",
    "]\n",
    "\n",
    "categorical_cols = [\n",
    "    'ocean_proximity',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, c in enumerate(X_train.columns):\n",
    "    print(i, c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Self\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class ComputeFeatures(BaseEstimator, TransformerMixin):\n",
    "    '''Computes new features from the existing features.'''\n",
    "    TOTAL_ROOMS_COLUMN = 3\n",
    "    TOTAL_BEDROOMS_COLUMN = 4\n",
    "    POPULATION_COLUMN = 5\n",
    "    HOUSEHOLDS_COLUMN = 6\n",
    "\n",
    "    def fit(self, X: np.array, y: Any = None) -> Self:\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: np.array) -> np.array:\n",
    "        rooms_per_household = \\\n",
    "            X[:, self.TOTAL_ROOMS_COLUMN] / X[:, self.HOUSEHOLDS_COLUMN]\n",
    "        bedrooms_per_household = \\\n",
    "            X[:, self.TOTAL_BEDROOMS_COLUMN] / X[:, self.HOUSEHOLDS_COLUMN]\n",
    "        bedrooms_per_room = \\\n",
    "            X[:, self.TOTAL_BEDROOMS_COLUMN] / X[:, self.TOTAL_ROOMS_COLUMN]\n",
    "        population_per_household = \\\n",
    "            X[:, self.POPULATION_COLUMN] / X[:, self.HOUSEHOLDS_COLUMN]\n",
    "\n",
    "        X = np.c_[\n",
    "            X,\n",
    "            rooms_per_household,\n",
    "            bedrooms_per_household,\n",
    "            bedrooms_per_room,\n",
    "            population_per_household,\n",
    "        ]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('features', ComputeFeatures()),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('encoder', OneHotEncoder()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessing_pipe = ColumnTransformer(transformers=[\n",
    "    ('num', num_pipeline, numerical_cols),\n",
    "    ('cat', cat_pipeline, categorical_cols),\n",
    "],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolha de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train,\n",
    "                                                  y_train,\n",
    "                                                  test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipe),\n",
    "    ('regression', LinearRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipe),\n",
    "    ('regression', DecisionTreeRegressor(random_state=42)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipe),\n",
    "    ('regression', RandomForestRegressor(random_state=42)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "\n",
    "def train_and_evaluate_model(\n",
    "    model: BaseEstimator,\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: np.array,\n",
    "    X_val: pd.DataFrame,\n",
    "    y_val: np.array,\n",
    ") -> float:\n",
    "    '''Trains and evaluates a model.\n",
    "\n",
    "    Args:\n",
    "        model: A scikit-learn model.\n",
    "        X_train: The training features.\n",
    "        y_train: The training target.\n",
    "        X_val: The validation features.\n",
    "        y_val: The validation target.\n",
    "\n",
    "    Returns:\n",
    "        The root mean squared error of the model on the validation set.\n",
    "    '''\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    return root_mean_squared_error(y_val, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_lin_reg = train_and_evaluate_model(lin_reg, X_train, y_train, X_val, y_val)\n",
    "rmse_tree_reg = train_and_evaluate_model(tree_reg, X_train, y_train, X_val,\n",
    "                                         y_val)\n",
    "rmse_forest_reg = train_and_evaluate_model(forest_reg, X_train, y_train, X_val,\n",
    "                                           y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Linear Regression RMSE: {rmse_lin_reg:.4f}')\n",
    "print(f'Decision Tree RMSE: {rmse_tree_reg:.4f}')\n",
    "print(f'Random Forest RMSE: {rmse_forest_reg:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_error_lin_reg = 100.0 * (10.0**rmse_lin_reg - 1.0)\n",
    "percentage_error_tree_reg = 100.0 * (10.0**rmse_tree_reg - 1.0)\n",
    "percentage_error_forest_reg = 100.0 * (10.0**rmse_forest_reg - 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Linear Regression Percentage Error: {percentage_error_lin_reg:.2f}%')\n",
    "print(f'Decision Tree Percentage Error: {percentage_error_tree_reg:.2f}%')\n",
    "print(f'Random Forest Percentage Error: {percentage_error_forest_reg:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
